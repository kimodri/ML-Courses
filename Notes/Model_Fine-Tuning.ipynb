{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461e406b-306f-4082-87f6-92a552507a04",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning\n",
    "\n",
    "- Learn several metrics and visualizing\n",
    "- Optimize classification and regression with hyperparameter tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6938cb8-186a-4c9c-bf7b-5886cf3334bb",
   "metadata": {},
   "source": [
    "## Why Metrics Do not Always Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743da00f-a344-452e-a18a-43f91fbf8e3d",
   "metadata": {},
   "source": [
    "Conflict on a dataframe with class imbalance may not work.\n",
    "\n",
    "Example: If your model is trained on dataset with 99% being `yes` and 1% being `no`, you could build a model that predicts none of the observation as `no` and if you use the simple ratio of correct / number of total observation, it could reflect a 99% accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0a41a-2314-4090-9231-c4fc4d6716b2",
   "metadata": {},
   "source": [
    "## Confusion Matrix in Assessing Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98caa3c9-1286-4c2f-b370-77736e5138d5",
   "metadata": {},
   "source": [
    "to be able to do confusion matrix and its metircs, we follow:\n",
    "- Import the `classification_report` and `confusion_matrix`\n",
    "- Intantiate a classification model\n",
    "- Fit\n",
    "- Predict\n",
    "- Print the confusion matrix\n",
    "- print the classification report\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556d02b-29f8-43b9-81d8-5ea5d4557fb3",
   "metadata": {},
   "source": [
    "The following are the tools/arguments use for confusion matrix and classification report:\n",
    "\n",
    "**Arguments**\r\n",
    "\r\n",
    "| Arguments       | Description                                                   | Syntax                                      |\r\n",
    "|----------------|---------------------------------------------------------------|---------------------------------------------|\r\n",
    "| y_true         | Actual labels for the test data                               | `confusion_matrix(y_true, y_pred)`          |\r\n",
    "| y_pred         | Predicted labels for the test data                            | `confusion_matrix(y_true, y_pred)`          |\r\n",
    "| labels         | List of labels to index the matrix                            | `confusion_matrix(y_true, y_pred, labels=)` |\r\n",
    "| target_names   | List of target names to index the report                      | `classification_report(y_true, y_pred, target_names=)` |\r\n",
    "| output_dict    | If True, return output as dict                                | `classification_report(y_true, y_pred, output_dict=)` |\r\n",
    "| digits         | Number of digits for formatting output                        | `classification_report(y_true, y_pred, digits=)` |\r\n",
    "\r\n",
    "**Functions**\r\n",
    "\r\n",
    "| Functions            | Description                                                   | Syntax                                      |\r\n",
    "|----------------------|---------------------------------------------------------------|---------------------------------------------|\r\n",
    "| confusion_matrix     | Computes the confusion matrix to evaluate the accuracy of a classification | `confusion_matrix(y_true, y_pred)`          |\r\n",
    "| classification_report| Builds a text report showing the main classification metrics  | `classification_report(y_true, y_pred, target_names=, output_dict=, digits=)` |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c75fe9-9193-47bc-bf27-cb49f6947815",
   "metadata": {},
   "source": [
    "## Confusion Matrix with Cross-Validation\n",
    "\n",
    "---\r\n",
    "\r\n",
    "- Aggregate the results from all folds to get a comprehensive evaluation of the model's performance.\r\n",
    "- Use k-fold cross-validation to split the data into k folds.\r\n",
    "- For each fold:\r\n",
    "  - Use the fold as the test set (`y_true`).\r\n",
    "  - Use the remaining k-1 folds as the training set.\r\n",
    "  - Train the model on the training set.\r\n",
    "  - Predict the labels for the test set (`y_pred`).\r\n",
    "  - Store the true and predicted labels.\r\n",
    "- Combine the true labels and predicted labels from all folds.\r\n",
    "- Compute the overall confusion matrix using the aggregated true and predicted labels.\r\n",
    "\r\n",
    "**Flow of Cross-Validation for Confusion Matrix:**\r\n",
    "\r\n",
    "1. **Initialize K-Fold Cross-Validation**: \r\n",
    "   - Define the number of folds (e.g., `kf = KFold(n_splits=5, shuffle=True, random_state=42)`).\r\n",
    "\r\n",
    "2. **Prepare Lists for Aggregation**:\r\n",
    "   - Initialize empty lists to store true and predicted labels (`all_y_true = []`, `all_y_pred = []`).\r\n",
    "\r\n",
    "3. **Iterate Through Folds**:\r\n",
    "   - For each fold:\r\n",
    "     - Split the data into training and testing sets.\r\n",
    "     - Train the model on the training set.\r\n",
    "     - Predict the labels for the test set.\r\n",
    "     - Append the true and predicted labels to the respective lists.\r\n",
    "\r\n",
    "4. **Aggregate Results**:\r\n",
    "   - Combine the true labels and predicted labels from all folds into single lists.\r\n",
    "\r\n",
    "5. **Compute Confusion Matrix**:\r\n",
    "   - Use the aggregated true and predicted labels to compute the overall confusion matrix (`cm = confusion_matrix(all_y_true, all_y_pred)`).\r\n",
    "\r\n",
    "**Example Code**:\r\n",
    "\r\n",
    "```python\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "# Create a sample DataFrame\r\n",
    "data = {\r\n",
    "    'Feature1': np.random.rand(100),\r\n",
    "    'Feature2': np.random.rand(100),\r\n",
    "    'Target': np.random.choice([0, 1], size=100)\r\n",
    "}\r\n",
    "df = pd.DataFrame(data)\r\n",
    "\r\n",
    "# Split the data into features (X) and target (y)\r\n",
    "X = df[['Feature1', 'Feature2']]\r\n",
    "y = df['Target']\r\n",
    "\r\n",
    "# Initialize KFold with 5 splits\r\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\r\n",
    "\r\n",
    "# Initialize lists to store true and predicted values\r\n",
    "all_y_true = []\r\n",
    "all_y_pred = []\r\n",
    "\r\n",
    "# Perform cross-validation\r\n",
    "for train_index, test_index in kf.split(X):\r\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n",
    "    y_train, y_test = y.iloc[test_index]\r\n",
    "    \r\n",
    "    # Instantiate and train the logistic regression model\r\n",
    "    model = LogisticRegression()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    # Predict the target values for the test set\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    \r\n",
    "    # Store the true and predicted values\r\n",
    "    all_y_true.extend(y_test)\r\n",
    "    all_y_pred.extend(y_pred)\r\n",
    "\r\n",
    "# Compute the overall confusion matrix\r\n",
    "cm = confusion_matrix(all_y_true, all_y_pred)\r\n",
    "\r\n",
    "print(\"Overall Confusion Matrix:\")\r\n",
    "print(cm)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae6a31-bad9-47a4-befb-f1fc298fbc21",
   "metadata": {},
   "source": [
    "## Logistic  Regression and ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699a707-f288-4da7-85d8-5ad745a74e5e",
   "metadata": {},
   "source": [
    "**Functions**  \r\n",
    "\r\n",
    "| Function               | Description                                      | Syntax                        |\r\n",
    "|------------------------|--------------------------------------------------|-------------------------------|\r\n",
    "| `LogisticRegression`   | Instantiates a logistic regression classifier   | `LogisticRegression()`        |\r\n",
    "| `fit`                 | Trains the model on training data                | `model.fit(X_train, y_train)` |\r\n",
    "| `predict`             | Makes predictions on test data                   | `model.predict(X_test)`       |\r\n",
    "| `predict_proba`       | Predicts class probabilities                     | `model.predict_proba(X_test)` |\r\n",
    "| `roc_curve`           | Computes ROC curve values                        | `roc_curve(y_test, y_pred_probs)` |\r\n",
    "| `roc_auc_score`       | Computes AUC score                               | `roc_auc_score(y_test, y_pred_probs)` |\r\n",
    "\r\n",
    "**Arguments**  \r\n",
    "\r\n",
    "| Argument              | Description                                        | Syntax                           |\r\n",
    "|----------------------|--------------------------------------------------|---------------------------------|\r\n",
    "| `X_train`           | Training data features                            | `model.fit(X_train, y_train)`  |\r\n",
    "| `y_train`           | Training data labels                              | `model.fit(X_train, y_train)`  |\r\n",
    "| `X_test`            | Test data features                                | `model.predict(X_test)`        |\r\n",
    "| `y_test`            | Test data labels                                  | `roc_curve(y_test, y_pred_probs)` |\r\n",
    "| `y_pred_probs`      | Predicted probabilities from `predict_proba`      | `roc_curve(y_test, y_pred_probs)` |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c318c2-e2d4-44cb-b760-5768375d95bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
